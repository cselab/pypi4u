<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  
  <title>Home - Pi4U</title>
  

  <link rel="shortcut icon" href="../img/favicon.ico">

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">

  
  <script>
    // Current page data
    var mkdocs_page_name = "Home";
    var mkdocs_page_input_path = "README.md";
    var mkdocs_page_url = "/README/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script>
  <script src="../js/theme.js"></script> 

  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="./" class="icon icon-home"> Pi4U</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <ul class="current">
          
            <li>
    <li class="toctree-l1 current">
        <a class="current" href="./">Home</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#pypi4u">PyPi4u</a></li>
                
                    <li><a class="toctree-l4" href="#getting-started">Getting started</a></li>
                
                    <li><a class="toctree-l4" href="#how-it-works">How it Works</a></li>
                
                    <li><a class="toctree-l4" href="#example-problem-demo">Example Problem - DEMO</a></li>
                
            
            </ul>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../getting_started/">Getting started</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../own_model/">How to implement your own model</a>
        
    </li>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="./">Pi4U</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="./">Docs</a> &raquo;</li>
    
      
    
    <li>Home</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="pypi4u">PyPi4u</h1>
<p>PyPi4u is inteded to provide the user with easy-to-use uncertainty quantification tools written in Python. 
It provides a covariance matrix adaptation evolution strategy implementation (CMA-ES) and a transitional markov-chain monte carlo (TMCMC) implementation to perform uncertainty quantification and parameter estimation. The CMA-ES implementation uses the covariance matrix adaptation evolution strategy to determine the maximum of the posterior probability distribution, which is defined as following: </p>
<p><img alt="equation" src="http://latex.codecogs.com/gif.latex?p%28hypothesis%7Cdata%2CI%29%20%5Cpropto%20p%28data%7Chypothesis%2CI%29%5Ctimes%20p%28hypothesis%7CI%29" /></p>
<p>The TMCMC algorithm avoids difficulties in sampling directly from the target posterior probability distribution by sampling from a series of intermediate probability distributions. This annealing process can be denoted by </p>
<ul>
<li>INSERT FORMULA</li>
</ul>
<p>The generated samples can then be used to determine the stochastic mean and variance. The stochastic mean of the multivariate distribution can be equated to the most-likely parameters/estimators given the data. </p>
<h2 id="getting-started">Getting started</h2>
<p>To download the implementations, please visit the github <a href="https://github.com/cselab/pypi4u">repository</a> and clone it. </p>
<h2 id="how-it-works">How it Works</h2>
<p>The following section explains the project's underlying structure and how the provided code can be used to make estimations of the model parameters. This explanation is further supported by a proceeding example, which illustrates how the scripts can be implemented.</p>
<h3 id="common-parameters">Common Parameters</h3>
<p>Both the CMA-ES and TMCMC implementation access a common parameter file, named <code>common_parameters.par</code>. The common parameter file, which needs to be filled out by the user, defines the problem and therefore forms the project's foundation. The structure of the common parameter file is depicted below. It consists of three sections; the model, priors and log-likelihood. </p>
<pre><code>[MODEL]
Number of model parameters = 3
model file = model_function.py
data file = data.txt 

[PRIORS]
# Set prior distribution
# prior distributions uniform normal

P1 = normal 4 2
P2 = normal 1 2
P3 = uniform 0 5
error_prior = uniform 0 2

[log-likelihood]
# error either proportional or constant
error = constant
</code></pre>

<p><strong>[MODEL]</strong> - In the model section the number of model parameters is to be defined. The model parameters are the number of unknown parameters in the model function. In other words the model parameters are the parameters that are to be predicted. For example if the model function is the following: </p>
<p><img alt="equation" src="http://latex.codecogs.com/gif.latex?f%28t%2C%5Ctheta_1%2C%5Ctheta_2%2C%5Ctheta_3%29%3Dt%5Ccdot%5Ctheta_3%5Ccdot%5Ccos%28%5Ctheta_1%5Ccdot%20t%29%20&amp;plus;%20%5Ctheta_2%5Ccdot%5Csin%28t%29" /> </p>
<p>The model parameters would be <img alt="equation" src="http://latex.codecogs.com/gif.latex?%5Ctheta_1%2C%5Ctheta_2%2C%5Ctheta_3" /> and thus the number of model parameters would be 3. The model file should be set equal to path of the python script that contains the function definition corresponding to the model function. Finally, the data file is the path to the text file that contains a list of input values and corresponding output values (function evaluations with noise).</p>
<p><strong>[PRIORS]</strong> - In this section the user is able to set the prior probability density functions of the estimators. The prior probability distribution functions can either be normal or uniform. They are assigned by writing to the parameter file P[number of parameter] = [normal] [mean] [variance] or P[number of parameter] = [uniform] [minimum] [maximum]. The error prior defines the prior knowledge available in regards to the noise that corrupts the data. Its definition is identical to that of the parameter priors, just that instead of P[number of parameter], the user must now set error_prior equal to a uniform or normal distribution.</p>
<p><strong>[log-likelihood]</strong> - In this section the error/noise that corrupts the data can be defined. A constant error means that the data is distorted by a constant term <img alt="equation" src="http://latex.codecogs.com/gif.latex?%5Cvarepsilon%5Csim%20%5Cmathcal%7BN%7D%280%2C%5C%2C%5Csigma%5E%7B2%7D%29" />. In the case of a proportional error, the magnitude of the error also depends on <em>t</em>, the independent variable, as it is defined as <img alt="equation" src="http://latex.codecogs.com/gif.latex?%5Cvarepsilon%20%5Ccdot%20t" />, where <img alt="equation" src="http://latex.codecogs.com/gif.latex?%5Cvarepsilon%5Csim%20%5Cmathcal%7BN%7D%280%2C%5C%2C%5Csigma%5E%7B2%7D%29" />. </p>
<h3 id="cma-parameters">CMA Parameters</h3>
<p>Besides setting the common parameters, the user must also define parameters specific to the implementation. The CMA parameters, which are stored in <code>CMA_parameters.par</code> file, are the following: </p>
<pre><code>[PARAMETERS]
#defining the parameters for CMA 

bounds = 0 10 #upper and lower bound, the parameters must be within these bounds 
x_0 = 5 5 5 5 #starting point, initial guess for the theta vector (the last entry of the vector corresponds to the guess of the error term)
sigma_0 = 5 #initial standard deviation
</code></pre>

<p>These specific parameters can be interpreted as following:
<em> <strong>Bounds</strong> - defines the lower and upper bound of the estimators. The values of all of the estimated parameters are restricted to this bound. The larger the bound the longer it will take for the CMA-ES algorithm to find the maximum of the posterior probability function. 
</em> <strong>x_0</strong> - this is a vector containing the initial guesses of the estimators. The vector size exceeds the number of model parameters by one. The variance introduced by the noise (<img alt="equation" src="http://latex.codecogs.com/gif.latex?%5Cvarepsilon%5Csim%20%5Cmathcal%7BN%7D%280%2C%5C%2C%5Csigma%5E%7B2%7D%29" />) is also an unknown that has to be predicted. It forms the last entry of theta vector. x_0 represents the starting point of the CMA-ES algorithm. Ultimately, the algorithm evolves from this guess towards the most-likely estimators. A rule of thumb is that the initial guesses should be in the middle of bound. If the lower bound is 0 and the upper bound is 10, the x_0 should be 5 5 5 5. 
* <strong>sigma_0</strong> - defines the initial standard deviation used by CMA-ES algorithm when making its initial guesses. </p>
<h3 id="tmcmc-parameters">TMCMC Parameters</h3>
<p>Besides the common parameters, also TMCMC requires additional parameters. They are included in the parameter file 'TMCMC.par' and are TMCMC specific parameters such as pop_size, bbeta = 0.04, tol_COV and BURN_IN. Further settings can be changed within the default settings folder.</p>
<h3 id="model-function">Model Function</h3>
<p>The model function needs to be defined by the user. It is a function that takes two arguments, an estimator vector of a given size (size is defined in common parameters) and <em>t</em>, and returns a float. For example: </p>
<pre><code>import math

def model_function(theta, time): #evaluates my model function for a given theta and time
    return time*theta[2]*math.cos(theta[0]*time) + theta[1]*math.sin(time)
</code></pre>

<h3 id="data-file">Data File</h3>
<p>The user needs to append a data file. This data file should be a text file that contains two columns, delimited by a space. The first column should be the value of the independent variable [<em>t</em>], while the second column should be corresponding function evaluation/measurement [<em>function evaluation</em>]. </p>
<h3 id="executing-the-code">Executing the Code</h3>
<p>After having filled in the parameter files, the estimators for the model parameters are simply obtained by either running <code>CMA_implementation.py</code> or <code>TMCMC_implementation.py</code>. On execution a text file named <code>CMA_estimators.txt</code> or <code>TMCMC_estimators.txt</code> will be created, in which the values of the estimators are stored. The last estimator in the file corresponds to the error estimator. It estimates the variance of the noise, within the data set. </p>
<h2 id="example-problem-demo">Example Problem - DEMO</h2>
<h3 id="generation-of-synthetic-data">Generation of Synthetic Data</h3>
<p>Synthetic data was generated from a predefined model function:</p>
<p><img alt="equation" src="http://latex.codecogs.com/gif.latex?f%28t%2C%5Ctheta_1%2C%5Ctheta_2%2C%5Ctheta_3%29%3Dt%5Ccdot%5Ctheta_3%5Ccdot%5Ccos%28%5Ctheta_1%5Ccdot%20t%29%20&amp;plus;%20%5Ctheta_2%5Ccdot%5Csin%28t%29" /> </p>
<p>The model parameters were set equal to <img alt="equation" src="http://latex.codecogs.com/gif.latex?%5Ctheta_1%20%3D%204%2C%20%5Ctheta_2%3D1%2C%20%5Ctheta_3%3D2" />. The function was then evaluated for <img alt="equation" src="http://latex.codecogs.com/gif.latex?t%20%3D%20%5B0.2%2C%200.4%2C%20%5Chdots%2C%204.0%5D" />. Additionally, random noise is introduced by simply adding epsilon to the function evaluations (constant error). The sum of the terms forms </p>
<p><img alt="equation" src="http://latex.codecogs.com/gif.latex?y_i%20%3D%20f%28t_i%2C%5Ctheta_1%2C%5Ctheta_2%2C%5Ctheta_3%29&amp;plus;%5Cvarepsilon" /></p>
<p>where epsilon equates to <img alt="equation" src="http://latex.codecogs.com/gif.latex?%5Cvarepsilon%20%5Csim%20%5Cmathcal%7BN%7D%28%5C0%2C1%29" /></p>
<p>Consequently, all obtained function evaluations are independently and identically distributed, following a normal distribution with a variance of one. The synthetic data is stored in a text document <code>data.txt</code>, which lists the input value <em>t</em> and the corresponding function value <em>f</em>. Both approaches use the synthetic data and the function definition <em>f</em> to approximate the values of the thetas and epsilon. </p>
<h3 id="common-parameters_1">Common Parameters</h3>
<pre><code>[MODEL]
Number of model parameters = 3
model file = model_function.py
data file = data.txt 

[PRIORS]
# Set prior distribution
# prior distributions uniform normal

P1 = normal 4 2
P2 = normal 1 2
P3 = uniform 0 5
error_prior = uniform 0 2

[log-likelihood]
# error either proportional or constant
error = constant
</code></pre>

<p><strong>[MODEL]</strong> - The model function consists of three parameters; therefore the number of model parameters was set to three. Additionally, the paths to the python model function and to the data file are given. </p>
<p><strong>[PRIORS]</strong> - In this exemplary case, the prior for the first parameter was taken to be a normal probability distribution with a mean of 4 and a variance of 2. The prior of the second parameter is also a normal probability distribution, but with a mean of 1 and a variance of 2. The third prior was set to a uniform probability distribution with a minimum of 0 and maximum of 5. Finally, the error prior was defined to be a uniform distribution with a minimum of 0 and maximum of 2. </p>
<p><strong>[log-likelihood]</strong> - The synthetic data was produced by corrupting the function evaluations with constant noise, which originated from a normal distribution with a mean of 0 and a variance of 1 (<img alt="equation" src="http://latex.codecogs.com/gif.latex?%5Cvarepsilon%20%5Csim%20%5Cmathcal%7BN%7D%28%5C0%2C1%29" />). Therefore, the error is set equal to a constant in the log-likelihood section of the common parameters. </p>
<h3 id="model-function-python-function">Model Function - Python Function</h3>
<p>The model function is defined as following: </p>
<p><img alt="equation" src="http://latex.codecogs.com/gif.latex?f%28t%2C%5Ctheta_1%2C%5Ctheta_2%2C%5Ctheta_3%29%3Dt%5Ccdot%5Ctheta_3%5Ccdot%5Ccos%28%5Ctheta_1%5Ccdot%20t%29%20&amp;plus;%20%5Ctheta_2%5Ccdot%5Csin%28t%29" /> </p>
<p>Therefore, the first argument of the function, the theta vector, needs to be a vector of size three, as there are three model parameters. The resulting function definition is as following: </p>
<pre><code>import math

def model_function(theta, time): #evaluates my model function for a given theta and time
    return time*theta[2]*math.cos(theta[0]*time) + theta[1]*math.sin(time)
</code></pre>

<p>Both the CMA-ES and the TMCMC implementation call this python function.  </p>
<h3 id="cma-es-implementation">CMA-ES Implementation</h3>
<p>To be able to implement the CMA-ES algorithm the CMA parameters must still be defined.  </p>
<pre><code>[PARAMETERS]
#defining the parameters for CMA 

bounds = 0 10 #upper and lower bound, the parameters must be within these bounds 
x_0 = 5 5 5 5 #starting point, initial guess for the theta vector (the last entry of the vector corresponds to the guess of the error term)
sigma_0 = 5 #initial standard deviation
</code></pre>

<p>In this example all parameters lie within the bound [0,10]. Furthermore, the rule of thumb is applied to obtain an initial starting guess for the theta vector. Finally, the initial standard deviation of the CMA-ES alogrithm was defined to be 5. </p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../getting_started/" class="btn btn-neutral float-right" title="Getting started">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>

  </div>

<div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
        <span style="margin-left: 15px"><a href="../getting_started/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>

</body>
</html>
